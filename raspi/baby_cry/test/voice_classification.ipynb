{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "from scikits.talkbox.features import mfcc\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pyaudio as pa\n",
    "import os\n",
    "\n",
    "random_state=24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音声ファイルimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "datapath = '../cry_data/devided_wav_data/'\n",
    "# datapath = 'devided_wav_data2/'\n",
    "\n",
    "for x in os.listdir(datapath):  \n",
    "    if '.wav' in x:\n",
    "        files.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各クラスのデータ数をそろえる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_count = 0\n",
    "ti_count = 0\n",
    "improved_files = []\n",
    "for f in files:\n",
    "    if '-hu.' in f:\n",
    "        if hu_count < 18:\n",
    "            hu_count += 1\n",
    "            improved_files.append(f)\n",
    "    elif '-ti.' in f:\n",
    "        if ti_count < 18:\n",
    "            ti_count += 1\n",
    "            improved_files.append(f)\n",
    "    else:\n",
    "        improved_files.append(f)\n",
    "\n",
    "del files\n",
    "files = improved_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mfccで特徴量とラベルのセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'hu':0, 'ti':1, 'dc':2}\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "x_seq = []\n",
    "for f in files:\n",
    "    x, sample_rate = sf.read(datapath + f)\n",
    "    x_seq.append(x)\n",
    "    x = np.clip(x, 1e-10, 1)\n",
    "    ceps,mspec,spec = mfcc(x, nwin=256, nfft=512, fs=8000, nceps=13)\n",
    "    X.append(np.mean(ceps, axis=0))\n",
    "    if '-hu.' in f:\n",
    "        y.append(label_dict['hu'])\n",
    "    elif '-ti.' in f:\n",
    "        y.append(label_dict['ti'])\n",
    "    else:\n",
    "        y.append(label_dict['dc'])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "welchメソッドによるパワースペクトルで特徴量とラベルのセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1dd91758b1f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnperseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnfft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwelch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hamming'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnperseg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnperseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnfft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy.signal\n",
    "\n",
    "label_dict = {'hu':0, 'ti':1, 'dc':2}\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "fs = 8000\n",
    "nperseg = 128\n",
    "nfft=1024\n",
    "for f in files:\n",
    "    x, sample_rate = sf.read(datapath + f)\n",
    "    freq, P = scipy.signal.welch(x, fs, window='hamming', nperseg=nperseg, nfft=nfft)\n",
    "    X.append(P)\n",
    "    if '-hu.' in f:\n",
    "        y.append(label_dict['hu'])\n",
    "    elif '-ti.' in f:\n",
    "        y.append(label_dict['ti'])\n",
    "    else:\n",
    "        y.append(label_dict['dc'])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 圧縮\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=13, random_state=random_state)\n",
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類器で学習、評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "precision = 0\n",
    "recall = 0\n",
    "f_value = 0\n",
    "\n",
    "n_splits = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    # clf = SVC(random_state=random_state, kernel='poly', probability=True)\n",
    "    # clf = RandomForestClassifier(n_estimators=498, random_state=random_state)\n",
    "    # clf = XGBClassifier(max_depth=5, learning_rate=0.06, n_estimators=200, seed=random_state)\n",
    "    # clf = KNeighborsClassifier(n_neighbors=3, weights='uniform', p=1)\n",
    "    # clf = QuadraticDiscriminantAnalysis()\n",
    "    #clf = MLPClassifier(hidden_layer_sizes=(50, 2), activation='tanh', random_state=random_state, alpha=0.01,\\\n",
    "    #                    learning_rate_init=0.01, max_iter=500, beta_1=0.8)\n",
    "    # clf = KNeighborsClassifier(algorithm='ball_tree',n_neighbors=3, weights='uniform', p=1)\n",
    "    clf = KNeighborsClassifier(algorithm='auto',n_neighbors=3, weights='uniform', p=1)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_valid)\n",
    "    precision += precision_score(y_valid, pred, average='micro')\n",
    "    recall += recall_score(y_valid, pred, average='micro')\n",
    "    f_value += f1_score(y_valid, pred, average='micro')\n",
    "\n",
    "precision = precision / float(n_splits)\n",
    "recall = recall / float(n_splits)\n",
    "f_value = f_value / float(n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59736044657097287"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59736044657097287"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "precision = 0\n",
    "recall = 0\n",
    "f_value = 0\n",
    "accuracy = 0\n",
    "\n",
    "n_splits = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    clf1 = SVC(random_state=random_state, kernel='poly', probability=True)\n",
    "    clf2 = RandomForestClassifier(n_estimators=498, random_state=random_state)\n",
    "    clf3 = XGBClassifier(max_depth=5, learning_rate=0.06, n_estimators=200, seed=random_state)\n",
    "    clf4 = KNeighborsClassifier(n_neighbors=3, weights='uniform', p=1)\n",
    "    clf5 = QuadraticDiscriminantAnalysis()\n",
    "    clf6 = MLPClassifier(hidden_layer_sizes=(50, 2), activation='tanh', random_state=random_state, alpha=0.01,\\\n",
    "                        learning_rate_init=0.01, max_iter=500, beta_1=0.8)\n",
    "    eclf = VotingClassifier(estimators=[('rf', clf2), ('knn', clf4), ('qda', clf5)], voting='hard')\n",
    "    eclf.fit(X_train, y_train)\n",
    "    pred = eclf.predict(X_valid)\n",
    "    precision += precision_score(y_valid, pred, average='macro')\n",
    "    recall += recall_score(y_valid, pred, average='macro')\n",
    "    f_value += f1_score(y_valid, pred, average='macro')\n",
    "    accuracy += accuracy_score(y_valid, pred)\n",
    "\n",
    "precision = precision / float(n_splits)\n",
    "recall = recall / float(n_splits)\n",
    "f_value = f_value / float(n_splits)\n",
    "accuracy = accuracy / float(n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66697767145135578"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71663419913419912"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65120333141230968"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_rf_knn_qda.pkl.cmp']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "clf2 = RandomForestClassifier(n_estimators=498, random_state=random_state)\n",
    "clf4 = KNeighborsClassifier(n_neighbors=3, weights='uniform', p=1)\n",
    "clf5 = QuadraticDiscriminantAnalysis()\n",
    "eclf = VotingClassifier(estimators=[('rf', clf2), ('knn', clf4), ('qda', clf5)], voting='hard')\n",
    "eclf.fit(X, y)\n",
    "joblib.dump(eclf, 'clf_rf_knn_qda.pkl.cmp', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
