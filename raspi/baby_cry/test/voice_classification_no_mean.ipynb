{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "from scikits.talkbox.features import mfcc\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pyaudio as pa\n",
    "import os\n",
    "\n",
    "random_state=123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音声ファイルimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "datapath = '../cry_data/devided_wav_data/'\n",
    "# datapath = 'devided_wav_data2/'\n",
    "\n",
    "for x in os.listdir(datapath):  \n",
    "    if '.wav' in x:\n",
    "        files.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各クラスのデータ数をそろえる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_count = 0\n",
    "ti_count = 0\n",
    "improved_files = []\n",
    "for f in files:\n",
    "    if '-hu.' in f:\n",
    "        if hu_count < 18:\n",
    "            hu_count += 1\n",
    "            improved_files.append(f)\n",
    "    elif '-ti.' in f:\n",
    "        if ti_count < 18:\n",
    "            ti_count += 1\n",
    "            improved_files.append(f)\n",
    "    else:\n",
    "        improved_files.append(f)\n",
    "\n",
    "del files\n",
    "files = improved_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mfccで特徴量とラベルのセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'hu':0, 'ti':1, 'dc':2}\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "x_seq = []\n",
    "for f in files:\n",
    "    x, sample_rate = sf.read(datapath + f)\n",
    "    x_seq.append(x)\n",
    "    x = np.clip(x, 1e-10, 1)\n",
    "    ceps,mspec,spec = mfcc(x, nwin=256, nfft=512, fs=8000, nceps=13)\n",
    "    if '-hu.' in f:\n",
    "        for cep in ceps:\n",
    "            X.append(cep)\n",
    "            y.append(label_dict['hu'])\n",
    "    elif '-ti.' in f:\n",
    "        for cep in ceps:\n",
    "            X.append(cep)\n",
    "            y.append(label_dict['ti'])\n",
    "    else:\n",
    "        for cep in ceps:\n",
    "            X.append(cep)\n",
    "            y.append(label_dict['dc'])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "welchメソッドによるパワースペクトルで特徴量とラベルのセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "label_dict = {'hu':0, 'ti':1, 'dc':2}\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "fs = 8000\n",
    "nperseg = 128\n",
    "nfft=1024\n",
    "for f in files:\n",
    "    x, sample_rate = sf.read(datapath + f)\n",
    "    freq, P = scipy.signal.welch(x, fs, window='hamming', nperseg=nperseg, nfft=nfft)\n",
    "    X.append(P)\n",
    "    if '-hu.' in f:\n",
    "        y.append(label_dict['hu'])\n",
    "    elif '-ti.' in f:\n",
    "        y.append(label_dict['ti'])\n",
    "    else:\n",
    "        y.append(label_dict['dc'])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 圧縮\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=13, random_state=random_state)\n",
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類器で学習、評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "precision = 0\n",
    "recall = 0\n",
    "f_value = 0\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    clf = SVC(random_state=random_state, kernel='poly', probability=True)\n",
    "    # clf = RandomForestClassifier(n_estimators=498, random_state=random_state)\n",
    "    # clf = XGBClassifier(max_depth=5, learning_rate=0.06, n_estimators=200, seed=random_state)\n",
    "    # clf = KNeighborsClassifier(n_neighbors=3, weights='uniform', p=1)\n",
    "    # clf = QuadraticDiscriminantAnalysis()\n",
    "    #clf = MLPClassifier(hidden_layer_sizes=(50, 2), activation='tanh', random_state=random_state, alpha=0.01,\\\n",
    "    #                    learning_rate_init=0.01, max_iter=500, beta_1=0.8)\n",
    "    # clf = KNeighborsClassifier(algorithm='ball_tree',n_neighbors=3, weights='uniform', p=1)\n",
    "    # clf = KNeighborsClassifier(algorithm='auto',n_neighbors=3, weights='uniform', p=1)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_valid)\n",
    "    precision += precision_score(y_valid, pred, average='micro')\n",
    "    recall += recall_score(y_valid, pred, average='micro')\n",
    "    f_value += f1_score(y_valid, pred, average='micro')\n",
    "\n",
    "precision = precision / float(n_splits)\n",
    "recall = recall / float(n_splits)\n",
    "f_value = f_value / float(n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "precision = 0\n",
    "recall = 0\n",
    "f_value = 0\n",
    "accuracy = 0\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    clf1 = SVC(random_state=random_state, kernel='poly', probability=True)\n",
    "    clf2 = RandomForestClassifier(n_estimators=498, random_state=random_state)\n",
    "    clf3 = XGBClassifier(max_depth=5, learning_rate=0.06, n_estimators=200, seed=random_state)\n",
    "    clf4 = KNeighborsClassifier(n_neighbors=3, weights='uniform', p=1)\n",
    "    clf5 = QuadraticDiscriminantAnalysis()\n",
    "    clf6 = MLPClassifier(hidden_layer_sizes=(50, 2), activation='tanh', random_state=random_state, alpha=0.01,\\\n",
    "                        learning_rate_init=0.01, max_iter=500, beta_1=0.8)\n",
    "    eclf = VotingClassifier(estimators=[('rf', clf2), ('knn', clf4), ('qda', clf5)], voting='hard')\n",
    "    eclf.fit(X_train, y_train)\n",
    "    pred = eclf.predict(X_valid)\n",
    "    precision += precision_score(y_valid, pred, average='macro')\n",
    "    recall += recall_score(y_valid, pred, average='macro')\n",
    "    f_value += f1_score(y_valid, pred, average='macro')\n",
    "    accuracy += accuracy_score(y_valid, pred)\n",
    "\n",
    "precision = precision / float(n_splits)\n",
    "recall = recall / float(n_splits)\n",
    "f_value = f_value / float(n_splits)\n",
    "accuracy = accuracy / float(n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8325900274732021"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83734416399285116"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83057091296578123"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_rf_knn_qda.pkl.cmp']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "clf2 = RandomForestClassifier(n_estimators=498, random_state=random_state)\n",
    "clf4 = KNeighborsClassifier(n_neighbors=3, weights='uniform', p=1)\n",
    "clf5 = QuadraticDiscriminantAnalysis()\n",
    "eclf = VotingClassifier(estimators=[('rf', clf2), ('knn', clf4), ('qda', clf5)], voting='hard')\n",
    "eclf.fit(X, y)\n",
    "joblib.dump(eclf, 'clf_rf_knn_qda.pkl.cmp', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
